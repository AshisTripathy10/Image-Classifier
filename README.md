Introduction: Fashion-MNIST is a dataset of Zalando's article images —consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label. The objective of the project is - to use the Fashion-MNIST data set to identify different fashion products from the given images with Neural Networks.

Importing the Modules: We start by importing the necessary modules: numpy for numerical operations and matplotlib.pyplot for data visualization. We also import tensorflow and keras, where TensorFlow acts as a toolkit for building and training deep learning models, and Keras offers a simpler interface to create and manage these models. We set the random seed for both NumPy and TensorFlow to ensure that our results are reproducible.

Loading the Dataset: We load the Fashion-MNIST dataset from Keras.The data is then split into training and test sets using the load_data() function. To ensure that the dataset is properly loaded, we check the shape of the training set, confirming that it contains 60,000 images, each with dimensions of 28x28 pixels, making it ready for further processing in our model.

Scaling the Data: We create the validation set by slicing the first 5,000 samples from X_train_full, scaling their pixel values to the 0-1 range, and storing them in X_valid with labels in y_valid. The remaining 55,000 samples are similarly scaled and stored in X_train, with labels in y_train. We confirm the dataset sizes by printing their shapes: 55,000 images for training, 5,000 for validation, and 10,000 for testing. Finally, we scale the test set X_test to match the preprocessing applied to the other sets.

Visualizing the Data: We define a class_names list to map the numerical labels of the dataset to their corresponding fashion item names (e.g., 0 to "T-shirt/top"). This makes it easier to interpret and display the output in a human-readable form. We then use Matplotlib's plt.imshow() function to plot an image from the dataset, using a 'binary' color map to effectively visualize the grayscale image. The image’s class label and name are printed using the class_names list, confirming the label matches the image (e.g., label 4 corresponds to "Coat"). Lastly, we create a grid of 40 images from the dataset, displaying each image alongside its class name, giving a clear overview of the different fashion items in the dataset.

Building the Model: We clear any previous session with keras.backend.clear_session() for a fresh start. We then build a neural network using Keras' Sequential API. The model includes a Flatten layer to reshape the 28x28 input images into a 1D array, followed by two Dense layers with 300 and 100 units respectively, both using ReLU activation to capture complex patterns. The final Dense layer has 10 units with softmax activation to produce class probabilities. We set the optimizer with keras.optimizers.SGD at a learning rate of 0.01 and compile the model using sparse_categorical_crossentropy (appropriate for integer labels) and accuracy as the performance metric.

Fitting the Model: We trained the model using model.fit on X_train and y_train for 30 epochs, validating with X_valid and y_valid. Initially, the training accuracy was 76.44%, with validation accuracy at 82.34%. By epoch 30, these improved to 91.91% and 89.42%, respectively. We accessed details about the first hidden layer, including its name, weights, and biases, to better understand the model’s learned features. We visualized accuracy and loss over epochs using a Pandas DataFrame and matplotlib. The training loss consistently decreased, while the validation loss stabilized after an initial drop, indicating good generalization with minimal overfitting. The alignment between training and validation accuracy further supported this.

Evaluating the Model: We evaluate the model's performance on the test set using model.evaluate, which provides the final loss and accuracy metrics. The test loss is approximately 0.336, and the accuracy is around 88.24%. Compared to the training and validation losses, the test loss is slightly higher, which is expected. We then make predictions for the first three test samples, obtaining class indices [9, 2, 1], which correspond to the class names 'Ankle boot', 'Pullover', and 'Trouser'. Finally, we visualize these predictions by plotting the images with their predicted labels displayed on top, allowing us to directly observe and verify the model’s classification results.


